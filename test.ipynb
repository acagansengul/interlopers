{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test PSO\n",
    "\n",
    "18 November 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import numpy as np\n",
    "\n",
    "# Import PySwarms (pip install pyswarms pyyaml)\n",
    "import pyswarms as ps\n",
    "from pyswarms.utils.functions import single_obj as fx\n",
    "\n",
    "# Some more magic so that the notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-18 21:57:03,565 - pyswarms.single.global_best - INFO - Optimize for 1000 iters with {'c1': 0.5, 'w': 0.9, 'c2': 0.3}\n",
      "pyswarms.single.global_best: 100%|██████████|1000/1000, best_cost=3.76e-44\n",
      "2019-11-18 21:57:04,672 - pyswarms.single.global_best - INFO - Optimization finished | best cost: 3.763289322434694e-44, best pos: [-1.29161489e-22 -1.44741850e-22]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.17 s, sys: 136 ms, total: 1.3 s\n",
      "Wall time: 1.11 s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "# Set-up hyperparameters\n",
    "options = {'c1': 0.5, 'c2': 0.3, 'w':0.9}\n",
    "\n",
    "# Call instance of PSO\n",
    "optimizer = ps.single.GlobalBestPSO(n_particles=10, dimensions=2, options=options)\n",
    "\n",
    "# Perform optimization\n",
    "cost, pos = optimizer.optimize(fx.sphere, iters=1000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.763289322434694e-44"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.29161489e-22, -1.44741850e-22])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a parameterized version of the classic Rosenbrock unconstrained optimzation function\n",
    "def rosenbrock_with_args(x, a, b, c=0):\n",
    "    f = (a - x[:, 0]) ** 2 + b * (x[:, 1] - x[:, 0] ** 2) ** 2 + c\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-18 21:59:05,354 - pyswarms.single.global_best - INFO - Optimize for 1000 iters with {'c1': 0.5, 'w': 0.9, 'c2': 0.3}\n",
      "pyswarms.single.global_best: 100%|██████████|1000/1000, best_cost=3.76e-44\n",
      "2019-11-18 21:59:06,469 - pyswarms.single.global_best - INFO - Optimization finished | best cost: 3.763289322434694e-44, best pos: [4.21758234e-15 7.38154598e-23]\n"
     ]
    }
   ],
   "source": [
    "cost, pos = optimizer.optimize(rosenbrock_with_args, 1000, a=1, b=100, c=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.763289322434694e-44, array([4.21758234e-15, 7.38154598e-23]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost, pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynesty test\n",
    "\n",
    "18 November 2019\n",
    "\n",
    "From the crash course at [this site](https://dynesty.readthedocs.io/en/latest/crashcourse.html#crash-course)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the dimensionality of our problem.\n",
    "ndim = 3\n",
    "\n",
    "# Define our 3-D correlated multivariate normal likelihood.\n",
    "C = np.identity(ndim)  # set covariance to identity matrix\n",
    "C[C==0] = 0.95  # set off-diagonal terms\n",
    "Cinv = np.linalg.inv(C)  # define the inverse (i.e. the precision matrix)\n",
    "lnorm = -0.5 * (np.log(2 * np.pi) * ndim +\n",
    "                np.log(np.linalg.det(C)))  # ln(normalization)\n",
    "\n",
    "# Is the lnorm important? I hope not...\n",
    "\n",
    "def loglike(x):\n",
    "    \"\"\"The log-likelihood function.\"\"\"\n",
    "\n",
    "    return -0.5 * np.dot(x, np.dot(Cinv, x)) + lnorm\n",
    "\n",
    "# Define our uniform prior.\n",
    "def ptform(u):\n",
    "    \"\"\"Transforms samples `u` drawn from the unit cube to samples to those\n",
    "    from our uniform prior within [-10., 10.) for each variable.\"\"\"\n",
    "\n",
    "    return 10. * (2. * u - 1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimate evidence and posterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dynesty\n",
    "\n",
    "# \"Static\" nested sampling.\n",
    "sampler = dynesty.NestedSampler(loglike, ptform, ndim)\n",
    "sampler.run_nested()\n",
    "sresults = sampler.results\n",
    "\n",
    "# \"Dynamic\" nested sampling.\n",
    "dsampler = dynesty.DynamicNestedSampler(loglike, ptform, ndim)\n",
    "dsampler.run_nested()\n",
    "dresults = dsampler.results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine static and dynamic results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dynesty import utils as dyfunc\n",
    "\n",
    "# Combine results from \"Static\" and \"Dynamic\" runs.\n",
    "results = dyfunc.merge_runs([sresults, dresults])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dynesty import plotting as dyplot\n",
    "\n",
    "# Plot a summary of the run.\n",
    "rfig, raxes = dyplot.runplot(results)\n",
    "\n",
    "# Plot traces and 1-D marginalized posteriors.\n",
    "tfig, taxes = dyplot.traceplot(results)\n",
    "\n",
    "# Plot the 2-D marginalized posteriors.\n",
    "cfig, caxes = dyplot.cornerplot(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Post-processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dynesty import utils as dyfunc\n",
    "\n",
    "# Extract sampling results.\n",
    "samples = results.samples  # samples\n",
    "weights = np.exp(results.logwt - results.logz[-1])  # normalized weights\n",
    "\n",
    "# Compute 10%-90% quantiles.\n",
    "quantiles = [dyfunc.quantile(samps, [0.1, 0.9], weights=weights)\n",
    "             for samps in samples.T]\n",
    "\n",
    "# Compute weighted mean and covariance.\n",
    "mean, cov = dyfunc.mean_and_cov(samples, weights)\n",
    "\n",
    "# Resample weighted samples.\n",
    "samples_equal = dyfunc.resample_equal(samples, weights)\n",
    "\n",
    "# Generate a new set of results with statistical+sampling uncertainties.\n",
    "results_sim = dyfunc.simulate_run(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test emcee parallelization\n",
    "\n",
    "17 November 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def log_prob(theta):\n",
    "    t = time.time() + np.random.uniform(0.005, 0.008)\n",
    "    while True:\n",
    "        if time.time() >= t:\n",
    "            break\n",
    "    return -0.5 * np.sum(theta ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emcee\n",
    "\n",
    "np.random.seed(42)\n",
    "initial = np.random.randn(32, 5)\n",
    "nwalkers, ndim = initial.shape\n",
    "nsteps = 100\n",
    "\n",
    "sampler = emcee.EnsembleSampler(nwalkers, ndim, log_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sampler.run_mcmc(initial, nsteps);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with Pool() as pool:\n",
    "    sampler = emcee.EnsembleSampler(nwalkers, ndim, log_prob, pool=pool)\n",
    "\n",
    "    state = sampler.run_mcmc(initial, nsteps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! I should have done this so much sooner!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with Pool() as pool:\n",
    "    new_sampler = emcee.EnsembleSampler(nwalkers, ndim, log_prob, pool=pool)\n",
    "    \n",
    "    new_sampler.run_mcmc(state, nsteps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
