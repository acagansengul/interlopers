{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emcee multifit\n",
    "17 November 2019\n",
    "\n",
    "Now that we've shown that `emcee` can fit a single subhalo or interloper pretty well (as an effective subhalo), let's see if we can handle multiple interlopers. For now, the multiple interlopers will all be at the same redshift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import emcee\n",
    "\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some standard python imports #\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cms\n",
    "#%matplotlib inline\n",
    "\n",
    "from lenstronomy.LensModel.lens_model import LensModel\n",
    "from lenstronomy.LensModel.Solver.lens_equation_solver import LensEquationSolver\n",
    "import lenstronomy.Plots.output_plots as lens_plot\n",
    "from lenstronomy.LightModel.light_model import LightModel\n",
    "import lenstronomy.Util.param_util as param_util\n",
    "from lenstronomy.PointSource.point_source import PointSource\n",
    "from lenstronomy.Data.pixel_grid import PixelGrid\n",
    "from lenstronomy.ImSim.image_model import ImageModel\n",
    "from lenstronomy.Data.psf import PSF\n",
    "import lenstronomy.Util.image_util as image_util\n",
    "from lenstronomy.Workflow.fitting_sequence import FittingSequence\n",
    "\n",
    "from astropy.cosmology import FlatLambdaCDM\n",
    "import astropy.units as u\n",
    "\n",
    "import copy\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ADD(z1,z2):\n",
    "    ## This is a function that computes the angular diameter distance\n",
    "    ## between two redshifts z1 and z2.\n",
    "    cosmo = FlatLambdaCDM(H0=70, Om0=0.316) \n",
    "    return cosmo.angular_diameter_distance_z1z2(z1,z2)\n",
    "\n",
    "def sigma_cr(zd,zs):\n",
    "    ## This function calculates the critical surface mass density at\n",
    "    ## redshift zd, relative to the source redshift zs.\n",
    "    const = 1.663e18*u.M_sun / u.Mpc##c^2/(4 pi G)\n",
    "    return const*(ADD(0,zs)/(ADD(zd,zs)*ADD(0,zd))) ##in units Msun/Mpc^2\n",
    "\n",
    "def gfunc(c):\n",
    "    ## This is the g(c) function that is defined\n",
    "    ## commonly in NFW profiles.\n",
    "    a = np.log(1.+c) - (c/(1.+c))\n",
    "    return 1./a\n",
    "\n",
    "def rs_angle(zd,rs): \n",
    "    ##takes in interloper redshift, gives you the scale redius in angular units\n",
    "    Dd = ADD(0,zd)\n",
    "    rs_mpc = rs*u.Mpc\n",
    "    return ((1./4.848e-6)*rs_mpc)/Dd ##gives in arcsec\n",
    "\n",
    "def alpha_s(m,rs,zd,zs):\n",
    "    ##takes in subhalo mass, scale radius, interloper redshift, source redshift\n",
    "    ##returns the angular deflection at scale radius\n",
    "    m_msun = m*u.M_sun\n",
    "    rs_mpc = rs*u.Mpc\n",
    "    con = (1./np.pi)*gfunc(200.)*(1.-np.log(2))\n",
    "    return m_msun/((rs_mpc**2.)*sigma_cr(zd,zs))\n",
    "\n",
    "def k_ext(N,m,A,zd,zs,pixsize):\n",
    "    ## FOR NOW THIS IS SET TO ZERO BECAUSE I CAN'T GET IT TO WORK\n",
    "    m_msun = m*u.M_sun\n",
    "    A_mpc2 = (pixsize**4)*(ADD(0.,zd)**2.)*A*((4.848e-6)**2.)  ##arcsec conversion\n",
    "    return 0.##-(N*m_msun)/(A_mpc2*sigma_cr(zd,zs))\n",
    "\n",
    "\n",
    "def xi_to_x(xi,z):\n",
    "    ##takes in physical coordinates (Mpc), turns it into angular coordinates (arcsec)\n",
    "    x = np.array(((xi*u.Mpc)/ADD(0.,z))/4.848e-6)\n",
    "    y = x.astype(np.float)\n",
    "    return y\n",
    "\n",
    "def x_to_xi(x,z):\n",
    "    ##takes in angular coordinates (arcsec), turns it into physical coordinates (Mpc)\n",
    "    return ((x*4.848e-6)*ADD(0,z))/u.Mpc\n",
    "\n",
    "def xi_to_pix(xi,z,pixsize,pixnum):\n",
    "    ## takes in physical coordinates (Mpc), identifies the appropriate pixel number\n",
    "    return (xi_to_x(xi,z))/pixsize + pixnum/2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Image-generation parameters**\n",
    "\n",
    "From some initial testing, it seems that if we generate interlopers close to the Einstein ring, then we can constrain the parameters much better (otherwise, there is a lot of degeneracy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(334) for N=1, j=50, generate subhalo very close to Einstein ring (limits for variables are not necessary)\n",
    "np.random.seed(333)\n",
    "\n",
    "## REDSHIFTS #######################################################################################\n",
    "Nit = 100 ##Number of different redshifts\n",
    "zds = np.linspace(0.01,0.99,Nit)\n",
    "####################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "## SOURCE PROPERTIES ###############################################################################\n",
    "r_sersic_source = 10.0\n",
    "e1s, e2s = param_util.phi_q2_ellipticity(phi=0.8, q=0.2)\n",
    "beta_ras, beta_decs = [1.7],[0.3]#this is the source position on the source plane\n",
    "\n",
    "n_sersic_source = 1.5\n",
    "\n",
    "## SOURCE-CLUMP PROPERTIES #########################################################################\n",
    "r_sersic_source_clumps = 1/3.\n",
    "N_clump = 0\n",
    "clumprandx = np.random.rand(N_clump)\n",
    "clumprandy = np.random.rand(N_clump)\n",
    "\n",
    "source_scatter = 1. ## This is how wide the scatter of the clumps over the smooth source\n",
    "\n",
    "n_sersic_source_clumps = 1.5\n",
    "\n",
    "####################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "## LENS PROPERTIES #################################################################################\n",
    "theta_lens = 10.\n",
    "zl = 0.2\n",
    "r_theta_lens = x_to_xi(theta_lens,zl)\n",
    "e1, e2 = param_util.phi_q2_ellipticity(phi=-0.9, q=0.8)\n",
    "gamma = 2.\n",
    "\n",
    "center_lens_x, center_lens_y = 0.,0.\n",
    "####################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "## IMAGE PROPERTIES ################################################################################\n",
    "pixsize = 0.2\n",
    "####################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "## INTERLOPER PROPERTIES ########################################################################### \n",
    "N = 2 ##Number of perturbers\n",
    "M = 1 ##Averaging different realizations\n",
    "\n",
    "disc_size = 2. ##  interlopers are randomly distributed to a disk that is this\n",
    "               ##  this times bigger than the einstein radius of the lens\n",
    "# Perturbers are uniformly distributed within a disk of radius `disc_size * r_theta_lens`\n",
    "r2s = ((disc_size*r_theta_lens)**2.)*(np.random.rand(N,M))\n",
    "# let's cheat to make this more interesting (TODO: change this back)\n",
    "#r2s = (r_theta_lens**2.)*np.random.uniform(0,.1,size=(N,M))\n",
    "\n",
    "\n",
    "rss = np.sqrt(r2s)\n",
    "theta_p = 2.*np.pi*(np.random.rand(N,M))\n",
    "xs = rss*np.cos(theta_p)\n",
    "ys = rss*np.sin(theta_p)\n",
    "xpixs = np.zeros([Nit,N,M]) # will add pixel values in the next cell\n",
    "ypixs = np.zeros([Nit,N,M]) #\n",
    "####################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specific image $-$ choose `j`, `k`\n",
    "Note that we'll be choosing one specific redshift and one specific statistic for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 19 # arbitrary choice (loop over redshifts) (19 is where zd \\approx zl)\n",
    "k = 0 # also arbitrary choice (loop over statistics)\n",
    "\n",
    "beta_ra, beta_dec = beta_ras[0], beta_decs[0]\n",
    "\n",
    "xpixs[j] = xi_to_pix(xs,zds[j],pixsize,200)   ## AT THAT REDSHIFT CALCULATING THE INTERLOPER\n",
    "ypixs[j] = xi_to_pix(ys,zds[j],pixsize,200)   ## POSITIONS. (THEY ARE RANDOMLY GENERATED IN THE EARLIER BOX)\n",
    "\n",
    "m =1.0e7 # mass of interlopers\n",
    "if j == 0:\n",
    "    m = 0. # so that the first image will be pure (no interloper effect)\n",
    "zs = 1.\n",
    "zd = zds[j] # interloper redshift\n",
    "rs = 0.001  # interloper scale radius r_s\n",
    "A = 80**2 ## in arcsec ## IGNORE THIS, THIS WAS FOR NEGATIVE CONVERGENCE\n",
    "\n",
    "kext = float(k_ext(N,m,A,zl,zs,pixsize))\n",
    "rsang = float(rs_angle(zd,rs))\n",
    "alphars = float(alpha_s(m,rs,zd,zs))\n",
    "\n",
    "## Setting lens_model_list and redshift_list\n",
    "lens_model_main = ['SPEP']\n",
    "lens_model_interlopers = ['CONVERGENCE']+['NFW' for i in range(N)]\n",
    "redshift_main = [zl]\n",
    "redshift_interlopers = [zd]+[zd for i in range(N)]\n",
    "# (unfortunately, we need to give the redshifts in increasing order, so we have two cases)\n",
    "if zl >= zd:\n",
    "    lens_model_list = lens_model_interlopers + lens_model_main\n",
    "    redshift_list = redshift_interlopers + redshift_main\n",
    "else:\n",
    "    lens_model_list = lens_model_main + lens_model_interlopers\n",
    "    redshift_list = redshift_main + redshift_interlopers\n",
    "\n",
    "\n",
    "z_source = zs\n",
    "\n",
    "lensModel_mp = LensModel(lens_model_list=lens_model_list,\n",
    "                         z_source=z_source,\n",
    "                         lens_redshift_list=redshift_list, \n",
    "                         multi_plane=True)\n",
    "\n",
    "kwargs_spep = {'theta_E': theta_lens, 'e1': e1, 'e2': e2, \n",
    "               'gamma': gamma, 'center_x': center_lens_x, 'center_y': center_lens_y}\n",
    "kwargs_conv ={'kappa_ext': kext}\n",
    "\n",
    "### NFW kwargs for the interlopers\n",
    "kwargs_main_lens = [kwargs_spep]\n",
    "kwargs_interlopers = [kwargs_conv] # (+ will append interlopers)\n",
    "for i in range(N):\n",
    "    center_nfw_x = xi_to_x(xs[i,k],zd)\n",
    "    center_nfw_y = xi_to_x(ys[i,k],zd)\n",
    "\n",
    "    kwargs_nfw = {'Rs':rsang,'alpha_Rs':alphars,'center_x': center_nfw_x, 'center_y': center_nfw_y}\n",
    "    kwargs_interlopers.append(kwargs_nfw)\n",
    "\n",
    "# (again, need to sort by redshift)\n",
    "if zl >= zd:\n",
    "    kwargs_lens = kwargs_interlopers + kwargs_main_lens\n",
    "else:\n",
    "    kwargs_lens = kwargs_main_lens + kwargs_interlopers\n",
    "\n",
    "########################################################################\n",
    "# set up the list of light models to be used #\n",
    "\n",
    "# SOURCE light\n",
    "source_light_model_list = ['SERSIC_ELLIPSE']\n",
    "for i in range(N_clump):\n",
    "    source_light_model_list.append('SERSIC')\n",
    "\n",
    "lightModel_source = LightModel(light_model_list = source_light_model_list)\n",
    "\n",
    "# LENS light\n",
    "lens_light_model_list = ['SERSIC_ELLIPSE']\n",
    "lightModel_lens = LightModel(light_model_list = lens_light_model_list)\n",
    "\n",
    "# SOURCE light kwargs\n",
    "kwargs_light_source = [{'amp': 1000., 'R_sersic': r_sersic_source, 'n_sersic': n_sersic_source, \n",
    "                      'e1': e1s, 'e2': e2s, 'center_x': beta_ra , 'center_y': beta_dec}]\n",
    "for i in range(N_clump):\n",
    "    kwargs_light_source.append({'amp': 1000, 'R_sersic': r_sersic_source_clumps, 'n_sersic': n_sersic_source_clumps,\n",
    "                                'center_x': beta_ra+source_scatter*(clumprandx[i]-.5), \n",
    "                                'center_y': beta_dec+source_scatter*(clumprandy[i]-.5)})\n",
    "\n",
    "# LENS light kwargs\n",
    "kwargs_light_lens = [{'amp': 1500, 'R_sersic': theta_lens, 'n_sersic': gamma, \n",
    "                      'e1': e1, 'e2': e2, 'center_x': center_lens_x , 'center_y': center_lens_y}]\n",
    "\n",
    "# evaluate surface brightness at a specific position #\n",
    "#flux = lightModel_lens.surface_brightness(x=1, y=1, kwargs_list=kwargs_light_lens)\n",
    "\n",
    "deltaPix = pixsize ###aLSO PIXSIze size of pixel in angular coordinates #\n",
    "\n",
    "# setup the keyword arguments to create the Data() class #\n",
    "ra_at_xy_0, dec_at_xy_0 = -20, -20 # coordinate in angles (RA/DEC) at the position of the pixel edge (0,0)\n",
    "transform_pix2angle = np.array([[1, 0], [0, 1]]) * deltaPix  # linear translation matrix of a shift in pixel in a shift in coordinates\n",
    "kwargs_pixel = {'nx': 200, 'ny': 200,  # number of pixels per axis\n",
    "                'ra_at_xy_0': ra_at_xy_0,  # RA at pixel (0,0)\n",
    "                'dec_at_xy_0': dec_at_xy_0,  # DEC at pixel (0,0)\n",
    "                'transform_pix2angle': transform_pix2angle} \n",
    "pixel_grid = PixelGrid(**kwargs_pixel)\n",
    "# return the list of pixel coordinates #\n",
    "x_coords, y_coords = pixel_grid.pixel_coordinates\n",
    "# compute pixel value of a coordinate position #\n",
    "x_pos, y_pos = pixel_grid.map_coord2pix(ra=0, dec=0)\n",
    "# compute the coordinate value of a pixel position #\n",
    "ra_pos, dec_pos = pixel_grid.map_pix2coord(x=20, y=10)\n",
    "\n",
    "# import the PSF() class #\n",
    "\n",
    "kwargs_psf = {'psf_type': 'GAUSSIAN',  # type of PSF model (supports 'GAUSSIAN' and 'PIXEL')\n",
    "              'fwhm': 0.01,  # full width at half maximum of the Gaussian PSF (in angular units)\n",
    "              'pixel_size': deltaPix  # angular scale of a pixel (required for a Gaussian PSF to translate the FWHM into a pixel scale)\n",
    "             }\n",
    "psf = PSF(**kwargs_psf)\n",
    "# return the pixel kernel correspon\n",
    "kernel = psf.kernel_point_source\n",
    "\n",
    "####################################################################################\n",
    "\n",
    "# import the ImageModel class #\n",
    "\n",
    "# define the numerics #\n",
    "kwargs_numerics = {'supersampling_factor': 1, # each pixel gets super-sampled (in each axis direction) \n",
    "                  'supersampling_convolution': False}\n",
    "# initialize the Image model class by combining the modules we created above #\n",
    "imageModel = ImageModel(data_class=pixel_grid, psf_class=psf, lens_model_class=lensModel_mp,\n",
    "                        source_model_class=lightModel_source,\n",
    "                        lens_light_model_class=lightModel_lens,\n",
    "                        kwargs_numerics=kwargs_numerics)\n",
    "# simulate image with the parameters we have defined above #\n",
    "image = imageModel.image(kwargs_lens=kwargs_lens, kwargs_source=kwargs_light_source,\n",
    "                         kwargs_lens_light=kwargs_light_lens)#, kwargs_ps=kwargs_ps)\n",
    "\n",
    "plt.imshow(image); plt.show()\n",
    "plt.imshow(np.log(image)); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In principle, we would make the image noisy here, but we'll skip that step for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('zl >= zd', zl >= zd)\n",
    "\n",
    "#N = 2 # number of subhalos to fit to\n",
    "print(N)\n",
    "print('zd', zd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume 1 interloper/subhalo for now\n",
    "lens_model_fit_list = ['SPEP']+['NFW']*N if zl < zd else ['NFW']*N+['SPEP']\n",
    "lens_model_fit = LensModel(lens_model_list=lens_model_fit_list,\n",
    "                         z_source=z_source, multi_plane=False)\n",
    "image_model_fit = ImageModel(data_class=pixel_grid, psf_class=psf, lens_model_class=lens_model_fit,\n",
    "                        source_model_class=lightModel_source,\n",
    "                        lens_light_model_class=lightModel_lens,\n",
    "                        kwargs_numerics=kwargs_numerics)\n",
    "\n",
    "def gen_image_macro(kwargs_lens_model): # rewrite the cell above as a function of the lens kwargs\n",
    "    image = image_model_fit.image(kwargs_lens=kwargs_lens_model, kwargs_source=kwargs_light_source,\n",
    "                         kwargs_lens_light=kwargs_light_lens)#, kwargs_ps=kwargs_ps)\n",
    "    return image\n",
    "\n",
    "def error(image1, image2):\n",
    "    assert(image1.shape == image2.shape)\n",
    "    \n",
    "    skipidx = 20100 # todo maybe undo this\n",
    "    \n",
    "    diffsq = (image1 - image2).flatten()**2\n",
    "    return np.sum(diffsq[:skipidx]) + np.sum(diffsq[skipidx+1:])\n",
    "\n",
    "def args_to_img(args):\n",
    "    assert(len(args) == 2*N+2)\n",
    "    rsang = args[0]\n",
    "    alphars = args[1]\n",
    "    xs = args[2:N+2]\n",
    "    ys = args[N+2:]\n",
    "    \n",
    "    my_spep = kwargs_spep\n",
    "    my_nfw_list = []\n",
    "    for i in range(N):\n",
    "        my_nfw = {'Rs': rsang, 'alpha_Rs': alphars,\n",
    "                  'center_x': xs[i], 'center_y': ys[i]}\n",
    "        my_nfw_list.append(my_nfw)\n",
    "\n",
    "    image_macro = gen_image_macro([my_spep]+my_nfw_list if zl < zd else my_nfw_list+[my_spep])\n",
    "    return image_macro\n",
    "\n",
    "def in_limits(args):\n",
    "    xs = args[2:N+2]\n",
    "    ys = args[N+2:]\n",
    "    pos_lim = 300 #np.inf\n",
    "    \n",
    "    if args[0] < 0 or args[1] < 0: return False\n",
    "    elif np.any(abs(xs) > pos_lim) or np.any(abs(ys) > pos_lim): return False\n",
    "    elif args[0] > 5: return False # TODO: figure out what reasonable limits are\n",
    "    elif args[1] > .1: return False # TODO: ditto\n",
    "    else: return True\n",
    "\n",
    "def log_prob(args):\n",
    "    if not in_limits(args):\n",
    "        return -np.inf\n",
    "    else:\n",
    "        err = error(image, args_to_img(args))\n",
    "    return -err #note: can make walkers go closer to the optimum by multiplying the err function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = ['rsang', 'alphars'] + ['center_x']*N + ['center_y']*N\n",
    "\n",
    "ndim = len(keys)\n",
    "\n",
    "means = [rsang, alphars]+[0]*(2*N)\n",
    "\n",
    "randomness = .01\n",
    "cov = 0.5 - randomness * np.random.rand(ndim**2).reshape((ndim,ndim))\n",
    "cov = np.triu(cov)\n",
    "cov += cov.T - np.diag(cov.diagonal())\n",
    "cov = np.dot(cov,cov)\n",
    "\n",
    "for i in range(ndim):\n",
    "    for j in range(ndim):\n",
    "        keys_ij = [keys[i], keys[j]]\n",
    "        \n",
    "        ratio = 1\n",
    "        for key in keys_ij:\n",
    "            if key == 'rsang':\n",
    "                ratio *= .03\n",
    "            elif key == 'alphars':\n",
    "                ratio *= .003\n",
    "            else:\n",
    "                ratio *= 1\n",
    "        cov[i,j] *= ratio\n",
    "\n",
    "plt.imshow(cov); plt.colorbar(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nwalkers = 40\n",
    "p0 = means + np.sqrt(np.diag(cov)) * (np.random.rand(nwalkers, ndim)-.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with Pool() as pool:\n",
    "    sampler = emcee.EnsembleSampler(nwalkers, ndim, log_prob, pool=pool)\n",
    "    state = sampler.run_mcmc(p0, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with Pool() as pool:\n",
    "    new_sampler = emcee.EnsembleSampler(nwalkers, ndim, log_prob, args=[], pool=pool)\n",
    "    state2 = new_sampler.run_mcmc(state, 200)\n",
    "sampler = new_sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with Pool() as pool:\n",
    "    new_sampler = emcee.EnsembleSampler(nwalkers, ndim, log_prob, args=[], pool=pool)\n",
    "    state3 = new_sampler.run_mcmc(state2, 200)\n",
    "sampler = new_sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with Pool() as pool:\n",
    "    new_sampler = emcee.EnsembleSampler(nwalkers, ndim, log_prob, args=[], pool=pool)\n",
    "    state4 = new_sampler.run_mcmc(state3, 2000)\n",
    "sampler = new_sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, key in enumerate(keys):\n",
    "    print('key', key)\n",
    "    for j in range(nwalkers):\n",
    "        plt.plot(sampler.chain[j,:,i], alpha = .2)\n",
    "    #plt.ylim(-50,50)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(nwalkers):\n",
    "    plt.plot(sampler.lnprobability[j,:], alpha=.3, color='xkcd:purple')\n",
    "    \n",
    "#plt.ylim(-20,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Show distribution of last log probs ##\n",
    "\n",
    "# last_lprobs = sampler.lnprobability[:,-1]\n",
    "# print(sorted(last_lprobs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate covariance matrix for our sample ##\n",
    "\n",
    "# xs = sampler.chain[:,:,0].flatten()\n",
    "# vars_data = [sampler.chain[:,:,i].flatten() for i in range(ndim)]\n",
    "# sample_cov = np.cov(np.vstack(vars_data))\n",
    "# plt.imshow(np.log(abs(sample_cov))); plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boundaries = np.linspace(-20,5,50)\n",
    "\n",
    "## \"Residuals\" compared to true image\n",
    "\n",
    "print('Compared to TRUE')\n",
    "\n",
    "for j in range(nwalkers)[:2]:\n",
    "#     print('before')\n",
    "#     plt.imshow(args_to_img(sampler.chain[j,0,:])); plt.colorbar(); plt.show()\n",
    "#     print('after')\n",
    "#     plt.imshow(args_to_img(sampler.chain[j,-1,:])); plt.colorbar(); plt.show()\n",
    "#     print('before, error=',error(args_to_img(sampler.chain[j,0,:]),image))\n",
    "#     plt.imshow(np.log(abs(args_to_img(sampler.chain[j,0,:])-image))); plt.colorbar(boundaries=boundaries); plt.show()\n",
    "    print('after, error=',error(args_to_img(sampler.chain[j,-1,:]),image))\n",
    "    plt.imshow(np.log(abs(args_to_img(sampler.chain[j,-1,:])-image))); plt.colorbar(boundaries=boundaries); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no subhalos\n",
    "nfw_idx = 2 if zl < zd else 1\n",
    "nosub_args = [rsang, 0]+[kwargs_lens[nfw_idx+i]['center_x'] for i in range(N)]+[kwargs_lens[nfw_idx+i]['center_y'] for i in range(N)]\n",
    "print('null args', nosub_args)\n",
    "nosub_img = args_to_img(nosub_args)\n",
    "print('null error', error(nosub_img, image))\n",
    "plt.imshow(np.log(abs(nosub_img - image))); plt.colorbar(boundaries=boundaries); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## \"Residuals\" compared to no-subhalos image ##\n",
    "print('Compared to NOSUB')\n",
    "\n",
    "for j in range(nwalkers)[:2]:\n",
    "#     print('before')\n",
    "#     plt.imshow(args_to_img(sampler.chain[j,0,:])); plt.colorbar(); plt.show()\n",
    "#     print('after')\n",
    "#     plt.imshow(args_to_img(sampler.chain[j,-1,:])); plt.colorbar(); plt.show()\n",
    "#     print('before, error=',error(args_to_img(sampler.chain[j,0,:]),image))\n",
    "#     plt.imshow(np.log(abs(args_to_img(sampler.chain[j,0,:])-nosub_img))); plt.colorbar(boundaries=boundaries); plt.show()\n",
    "    print('after, error=',error(args_to_img(sampler.chain[j,-1,:]),image))\n",
    "    plt.imshow(np.log(abs(args_to_img(sampler.chain[j,-1,:])-nosub_img))); plt.colorbar(boundaries=boundaries); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like it's just not quite working... I think it looks qualitatively right when the interlopers are in front of the lens at least."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('chains.p', 'wb') as f:\n",
    "#     pickle.dump(sampler, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"truth\"-level (compared to truth image -- only really makes sense at zl \\approx zd)\n",
    "nfw_idx = 2 if zl < zd else 1 # index of first nfw lens (todo: check this)\n",
    "almost_truth_args = [rsang, alphars]+[kwargs_lens[nfw_idx+i]['center_x'] for i in range(N)]+[kwargs_lens[nfw_idx+i]['center_y'] for i in range(N)]\n",
    "print('almost truth args', almost_truth_args)\n",
    "almost_truth_img = args_to_img(almost_truth_args)\n",
    "print('almost truth error', error(almost_truth_img, image))\n",
    "plt.imshow(np.log(abs(almost_truth_img - image))); plt.colorbar(boundaries=boundaries); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In certain cases, the error is dominated by a single pixel, and this makes the total error pretty bad. Let's try an error function that ignores the very center? (This is pixel number 20100, if we flatten the image (and assume it's a 200x200 image).)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the following graphs may (or may not) include points from during the burn-in period! To make a graph we can trust, you should only include points from after when the MCMC started to converge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.loglog(sampler.chain[:,:,0].flatten(), sampler.chain[:,:,1].flatten(), 'o', alpha=.01)\n",
    "plt.xlabel('rsang')\n",
    "plt.ylabel('alphars')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** : get the graph above in terms of mass!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(sampler.chain[:,:,2].flatten(), sampler.chain[:,:,3].flatten(), alpha=.05, color='blue', label='First NFW position')\n",
    "plt.scatter(sampler.chain[:,:,4].flatten(), sampler.chain[:,:,5].flatten(), alpha=.05, color='red', label='Second NFW position')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(sampler.chain[:,:,4].flatten(), sampler.chain[:,:,5].flatten(), alpha=.05, color='red', label='Second NFW position')\n",
    "plt.scatter(sampler.chain[:,:,2].flatten(), sampler.chain[:,:,3].flatten(), alpha=.05, color='blue', label='First NFW position')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does this distinction imply that we're in just one of multiple local minima? I think so. (But why am I even making commentary when I know I'm going to change parameters and make a different-looking graph?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(sampler.chain[:,:,2].flatten() - sampler.chain[:,:,4].flatten(),\n",
    "            sampler.chain[:,:,3].flatten() - sampler.chain[:,:,5].flatten(),\n",
    "            alpha=.05)\n",
    "\n",
    "plt.xlabel(r'$\\Delta x$')\n",
    "plt.ylabel(r'$\\Delta y$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "* For `N=2`, in front of the lens (`j=10`), where we put the interlopers at 0.1 Einstein radius, we got two well-separated clusters, and we were bumping up against the `alphars < 0.1` limit. The solutions didn't intermix even though I see no reason why they shouldn't. (Is `emcee` purposefully breaking the symmetry under the hood? I don't think so.)\n",
    "* For `N=2`, at the lens (`j=19`), where we put the interlopers at 0.1 Einstein radius, we got two partially overlapping clusters, not bumping up against any particular limit. The error is much lower if we ignore the central pixel (position 20100) -- goes from about $75^2$ to about $2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
